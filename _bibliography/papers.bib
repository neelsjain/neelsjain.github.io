---
---
@article{bozeman2020multi,
 title={Multi-color forcing in graphs},
 author={Bozeman, Chassidy and Harris, Pamela E and Jain, Neel and Young, Ben and Yu, Teresa},
 journal={Graphs and Combinatorics},
 volume={36},
 number={6},
 pages={1855--1868},
 year={2020},
 year_pub={2020},
 publisher={Springer},
 pdf={https://arxiv.org/pdf/1912.02001.pdf},
 abbr={Springer},
}
@article{10793182,
  title={Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers}, 
  author={Singh, Siddharth and Singhania, Prajwal and Ranjan, Aditya and Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Jain, Neel and Hans, Abhimanyu and Shu, Manli and Tomar, Aditya and Goldstein, Tom and Bhatele, Abhinav},
  publisher={SC24: International Conference for High Performance Computing, Networking, Storage and Analysis (Gordon Bell Finalist)},
  journal={SC24: International Conference for High Performance Computing, Networking, Storage and Analysis (Gordon Bell Finalist)},
  year={2024},
  year_pub={2024},
  pdf={https://arxiv.org/pdf/2502.08145},
  abbr={SC24}
}
@article{chen2024genqa,
  title={GenQA: Generating Millions of Instructions from a Handful of Prompts},
  author={Chen, Jiuhai and Qadri, Rifaa and Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Zhou, Tianyi and Goldstein, Tom},
  journal={arXiv preprint arXiv:2406.10323},
  pdf={https://arxiv.org/pdf/2406.10323},
  year={2024},
  publisher={Under Review},
  abbr={arXiv},
  data={https://huggingface.co/collections/tomg-group-umd/genqa-66259bafd7b6076f66c46a6c}
}

@article{hans2024like,
  title={Be like a Goldfish, Don't Memorize! Mitigating Memorization in Generative LLMs},
  author={Hans, Abhimanyu and Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Kazemi, Hamid and Singhania, Prajwal and Singh, Siddharth and Somepalli, Gowthami and Geiping, Jonas and Bhatele, Abhinav and others},
  journal={arXiv preprint arXiv:2406.10209},
  pdf={https://arxiv.org/pdf/2406.10209},
  year={2024},
  journal={Neural Information Processing Systems},
  publisher={Neural Information Processing Systems},
  year_pub={2024},
  abbr={NeurIPS},
  code={https://github.com/ahans30/goldfish-loss},
}



@article{mcleish2024transformers,
  title={Transformers Can Do Arithmetic with the Right Embeddings},
  author={McLeish, Sean and Bansal, Arpit and Stein, Alex and Jain, Neel and Kirchenbauer, John and Bartoldson, Brian R and Kailkhura, Bhavya and Bhatele, Abhinav and Geiping, Jonas and Schwarzschild, Avi and others},
  pdf={https://arxiv.org/pdf/2405.17399},
  journal={Neural Information Processing Systems},
  publisher={Neural Information Processing Systems},
  abbr={NeurIPS},
  year_pub={2024},
  year={2024},
  code={https://github.com/mcleish7/arithmetic}
}

@article{jain2023NEFTune,
     title={NEFTune: Noisy Embeddings Improve Instruction Finetuning},
     author={Jain, Neel and Chiang, Ping-yeh and Wen, Yuxin and Kirchenbauer, John and Chu, Hong-Min and Somepalli, Gowthami and Bartoldson, Brian and Kailkhura, Bhavya and Schwarzschild, Avi and Saha, Aniruddha and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
     year={2023},
     year_pub={2024},
     journal={International Conference on Learning Representations},
     publisher={International Conference on Learning Representations},
     pdf={https://arxiv.org/pdf/2310.05914},
     abbr={ICLR},
     code={https://github.com/neelsjain/NEFTune},
}
@article{jain2023baseline,
     title={Baseline Defenses for Adversarial Attacks Against Aligned Language Models},
     author={Jain, Neel and Schwarzschild, Avi and Wen, Yuxin and Somepalli, Gowthami  and Kirchenbauer, John and Chiang, Ping-yeh and Goldblum, Micah and Saha, Aniruddha and Geiping, Jonas and Goldstein, Tom},
     year={2023},
     year_pub={2023},
     journal={arXiv preprint arXiv:2309.00614},
     publisher={Under Review},
     pdf={https://arxiv.org/pdf/2309.00614},
     abbr={arXiv},
     code={https://github.com/neelsjain/baseline-defenses}
}

@article{jain2023bring,
     title={Bring Your Own Data! Self-Supervised Evaluation for Large Language Models},
     author={Jain, Neel and Saifullah, Khalid and Wen, Yuxin and Kirchenbauer, John and Shu, Manli and Saha, Aniruddha and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
     year={2023},
     year_pub={2024},
     journal={Conference on Language Modeling},
     publisher={COLM},
     pdf={https://arxiv.org/pdf/2306.13651},
     abbr={COLM},
     code={https://github.com/neelsjain/BYOD},
}

@article{wen2023hard,
 title={Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery},
 author={Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
 journal={Neural Information Processing Systems},
 year={2023},
 year_pub={2023},
 publisher={Neural Information Processing Systems},
 abbr={NeurIPS},
 pdf={https://arxiv.org/pdf/2302.03668.pdf},
 code={https://github.com/YuxinWenRick/hard-prompts-made-easy},
 demo={https://huggingface.co/spaces/tomg-group-umd/pez-dispenser},
}

@article{jainvocab,
 title={How to Do a Vocab Swap? A Study of Embedding Replacement for Pre-trained Transformers},
 author={Jain, Neel and Kirchenbauer, John and Geiping, Jonas and Goldstein, Tom},
 year={2022},
 year_pub={2022},
 journal={Preprint},
 pdf={https://openreview.net/pdf?id=MsjB2ohCJO1}
}

@article{hoover2025dynaguard,
  title={DynaGuard: A Dynamic Guardrail Model With User-Defined Policies},
  author={Hoover, Monte and Baherwani, Vatsal and Jain, Neel and Saifullah, Khalid and Vincent, Joseph and Jain, Chirag and Rad, Melissa Kazemi and Bruss, C Bayan and Panda, Ashwinee and Goldstein, Tom},
  journal={arXiv preprint arXiv:2509.02563},
  year={2025},
  pdf={https://arxiv.org/abs/2509.02563},
  publisher={Under Review},
  abbr={arXiv},
  models={https://huggingface.co/collections/tomg-group-umd/dynaguard-68af4d916ae81d06ef774523}
}

@article{synk2025exploiting,
  title={Exploiting Sparsity for Long Context Inference: Million Token Contexts on Commodity GPUs},
  author={Synk, Ryan and Hoover, Monte and Kirchenbauer, John and Jain, Neel and Stein, Alex and Shu, Manli and Sanchez, Josue Melendez and Duraiswami, Ramani and Goldstein, Tom},
  journal={arXiv preprint arXiv:2502.06766},
  year={2024},
  pdf={https://arxiv.org/pdf/2502.06766},
  abbr={arXiv},

}

@article{geiping2025scaling,
  title={Scaling up test-time compute with latent reasoning: A recurrent depth approach},
  author={Geiping, Jonas and McLeish, Sean and Jain, Neel and Kirchenbauer, John and Singh, Siddharth and Bartoldson, Brian R and Kailkhura, Bhavya and Bhatele, Abhinav and Goldstein, Tom},
  journal={arXiv preprint arXiv:2502.05171},
  year={2025},
  year_pub={2025},
  pdf={https://arxiv.org/pdf/2502.05171},
  journal={Neural Information Processing Systems (Spotlight)},
  publisher={Neural Information Processing Systems},
  abbr={NeurIPS},  
}



@article{jain2025refusal,
title={Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models},
author={Neel Jain and Aditya Shrivastava and Chenyang Zhu and Daben Liu and Alfy Samuel and Ashwinee Panda and Anoop Kumar and Micah Goldblum and Tom Goldstein},
publisher={Second Conference on Language Modeling},
journal={Second Conference on Language Modeling},
year={2025},
year_pub={2025},
url={https://openreview.net/forum?id=Pbs4i3FgbD},
abbr={COLM}
}

@article{white2024livebench,
  title={LiveBench: A Challenging, Contamination-Free LLM Benchmark},
  author={White, Colin and Dooley, Samuel and Roberts, Manley and Pal, Arka and Feuer, Ben and Jain, Siddhartha and Shwartz-Ziv, Ravid and Jain, Neel and Saifullah, Khalid and Naidu, Siddartha and others},
  pdf={https://arxiv.org/pdf/2406.19314},
  year={2025},
  year_pub={2025},
  journal={International Conference on Learning Representations (Spotlight)},
  publisher={International Conference on Learning Representations},
  abbr={ICLR},
  blog={https://livebench.ai/},
}